<html>
<link rel="stylesheet" href="style.css">
<title>Halting Solution</title>


<h1 class="title"><a href="index.html" style="color: black; text-decoration: none; ">Halting Solution</a></h1>


<div class="container">

    <div class="content mono">

        <h2>How do Computers Work?</h2>

        <h3>An Introduction</h3>


        There is undue mystery in the operation of computers. For some reason, digital technology is seen as magical or
        too advanced to be understood by the layperson. This is not true. Computers are glorified engines or plumbing
        systems - they're complicated, but anyone with some attention and effort can learn its principles and
        operations. To begin our understanding, we will begin at the heart of the machine and work our way outward.
        <br><br>


        <h3>CPU - the heart of a computer</h3>
        <div class="essayPictureContainerRight" style=" margin-bottom:1%;">
            <img src="img/CPU_example.png"
                alt=" an example graph showing an irregular square wave, where the x axis is time and the y axis is power. Small dials showing high and low power are put on the Y axis for illustrative purposes."
                style="width:100%;">
            <div style="text-align:center" class="fontCorrect"><i>An example power reading from somewhere on a computer
                    chip, showing high and low signals over time.</i>
            </div>

        </div>
        All modern
        computers have a central hub where all data flows, we generally call that the computer chip or CPU (which stands
        for Central Processing Unit). Like
        water pressure through a pipe, electricity flows through this chip - when the electricity has higher power we
        call it a 1 (or True) and when it's low we call it 0 (or False). If you were to take an electric sensor and put
        it somewhere on a chip, you would see the power rise up and fall down eratically as the data is passed around.
        <br><br>
        The chip has many places where this electricity
        flows. There are many units in a CPU and each performs a specialized job, such as adding two numbers together or
        collecting data from somewhere else. At each of these places, the unit spends a duration of time listening to
        the electricity and performing its work. Because of these time-sensitive tasks, the whole system
        must be very tightly choreographed. <br><br>


        To synchronize everything, all parts of the chip listen to a clock which ticks off time at a very precise (and
        <i>incredibly</i> fast) rate. These ticks aren't used to measure periods of time, just to set a pace - so it's
        more like a metronome than a watch! This mentronome-clock is made by passing electricity through a quartz
        crystal, which causes the crystal to shake at a predictable speed. Every time the crystal completes an
        oscillation (the shake), each part of the chip knows to perform its next step and pass the electricity to the
        next
        unit in the system (this is done by re-broadcasting what it heard - a zero or a 1 - to the next person in the
        cpu pipe).
        <br><br>

        <img src="img/4004map.jpg" class="pico8Image" style="width:80%"
            alt="an image through a powerful microscope of a computer processor, showing many eched lines and components">
        <div style="text-align:center"><i>This is a very zoomed in picture of the inside of a <a
                    href="https://en.wikipedia.org/wiki/Intel_4004">intel 4004</a> chip - the first computer chip on the
                market (thanks MIT for releasing this picture!). If you look closely, you can see all the little paths
                the electricity must take, and the units where that electricity is processed.</i></div><br><br>
        So now we have a few basic ideas:
        <ul>
            <li>Computers have a core called a CPU where all processing occurs</li>
            <li>CPUs operate with electricty passing along special routes</li>
            <li>These routes connect different electronic parts which do different jobs</li>
            <li>When the electricity is high, the computer considers it a 1</li>
            <li>When the electricity is low, the computer considers it a 0</li>
            <li>the whole system is synchronized with a highly accurate clock</li>
        </ul>


        <h3>The Early History of Computers</h3>
        <div class="essayPictureContainerDouble">

            <div class="essayPictureDouble">
                <div style="bottom:0%">
                    <img src="img/punchcard_loom.jpg"
                        alt="image of a punchcard loom, showing a bundle of threads being fed into the loom on one side, and a series of heavy paper punchcards on the other."
                        style="width:100%">
                    <div style="text-align:center;bottom:0%;">
                        <i>A punchard operated loom. Image via <a
                                href="https://commons.wikimedia.org/w/index.php?search=punchcard+loom&title=Special%3ASearch&go=Go&ns0=1&ns6=1&ns12=1&ns14=1&ns100=1&ns106=1#/media/File:A_Jacquard_loom_showing_information_punchcards,_National_Museum_of_Scotland.jpg">wikimedia
                                commons</a></i>
                    </div>
                </div>
            </div>
            <div class="essayPictureDouble">
                <img src="img/luddites.jpg" style="width:100%"
                    alt="A black and white engraved illustration of two men swinging hammers at a loom.">
                <div style="text-align:center">
                    <i>Luddites destroying the looms. Image via <a
                            href="https://commons.wikimedia.org/w/index.php?search=luddite+loom+-pdf&title=Special:Search&profile=advanced&fulltext=1&advancedSearch-current=%7B%7D&ns0=1&ns6=1&ns12=1&ns14=1&ns100=1&ns106=1#/media/File:FrameBreaking-1812.jpg">wikimedia
                            commons</a></i>
                </div>
            </div>

        </div>
        <br><br>

        A central idea in computing theory is that information can be used to represent data or instructions - sort of
        like how the human voice can be used to describe something, or to tell someone what to do. All of the
        information in modern computers are stored in the format of zeroes and ones.
        <br><br>
        People sometimes make the mistake of assuming zeroes and ones (also known as binary) is somehow special.
        (<i>psst, it's not!</i>) The first computers actually used the numbers 0-9, and that history is a really useful
        tool for understanding how modern computers work. In fact, it was this early dependence on base 10 which killed
        the first computers before they had the chance to mature into a useful machine. <br><br>
        <div class="essayPictureContainerRight">
            <img src="img/analytical_engine.jpg" style="width:100%"
                alt="an image of an analytical engine, showing many complicated gears and metal arms.">
            <div style="text-align:center" class="fontCorrect"><i>Babbage and Lovelace's Difference Engine. Image via <a
                        href="https://commons.wikimedia.org/wiki/File:Babbages_Analytical_Engine,_1834-1871._(9660574685).jpg">wikimedia
                        commons</a></i>
            </div>

        </div>

        The precursor to computers were completely unrelated to calcuation - they were actually specialized kinds of
        industrial looms. Making fabric patterns requires a very complicated organization of colored thread to be woven
        together perfectly. Automated looms created in the early 19th century used cards with holes punched in them
        (punch cards) to mechanically shift what threads were placed where.

        <br><br> This machine was so advanced, it was an early form of automation which replaced the occupational roles
        many skilled laborors. In 1811 those workers began burning the looms in protest, and became known as <a
            href="https://en.wikipedia.org/wiki/Luddite">the luddites</a>, which to this day is used as a term to mean
        someone who is against technological progress. The question of production, labor, and automation, have always
        been embedded within computing - even in its progenitor the loom.

        <br><br>The luddites launched the loom into public awareness - including the salons of the upper clases, where
        aristocratic scholars could meet and share ideas. Charles Babbage was one such elite. In the loom, he saw the
        potential to connect his understanding of engines and mathematics to make a mechanical device which could solve
        math problems. Rather than punchcards representing threads, they could instead be used to represent numbers and
        mathematical operations which the loom could then solve like an abacus. He called his device the Analytical
        Engine.
        <br><br>
        As Babbage worked on his mechanical designs, he recruited the young socialite Ada Lovelace to formulate how the
        punchcards would operate. Lovelace was a mathematical prodigy and the daughter of Lord Byron (Her mother
        suffering a falling out with Byron, insisted her daughter learn mathematics - the furthest discipline from
        poetry she could conceive of), and is now thought of as the first computer programmer.
        <br><br>

        The analytical engine was never built - the hand made parts were cumbersome and expensive and government
        financing ceased prior to the assembly of a prototype. Similar to the arabic numeral system we are familiar
        with, his machine was in base 10. This required a complicated gearing system with 10 settings for each digit.
        Although we find it easier to operate in the world with ten digits, it was a structural hurdle which fatally
        complicated the analyitcal engine's design.

        <br><br>Those needing to perform simple calculation continued to
        rely on abacuses, slide rules, and other such handheld tools which though simple proved reliable and easy to
        make. It wasn't for another century that attention would return to the general-purpose computer.
        <br><br>

        <h3>Computing the War</h3>
        In 1930's Germany, Konrad Zuse built the first binary computer. Instead of focusing on a gearing system which
        suited our familiarity with base 10 counting, he simplified numbers to instead suit the machine. By developing
        his mechanisms to use base two, Zuse only needed to represent two numbers for each digit - a zero and a one.
        Having only two setting to support instead of ten opened the door to the numerous implementations of computers
        we have since seen.
        <br><br>
        <div style="padding-left:2%">
        <i>As an aside:
            Interestingly not unlike Babbage, Zuse lost his government funding due to the belief that his machine did
            not
            have strategic importance. The Third Reich felt that between their hand calculations and the enigma machine
            (an
            early encryption tool), no further investment in computation or ciphers was necessary for the war effort.
            The
            Allies thought differently, and broke Enigma using their own early proto-computer known as the Bombe. Also
            at this time, people imprisoned at Auschwitz were tatooed with IBM identification numbers. Both blessings and horrors have forever followed the wake of calculation machines.
</i></div>
        <br>
        So why did switching to binary produce more efficient calcuating machines? We'll cover that in the next essay,
        which focuses on how humans count numbers and why computers use base 2.
        <br><br>


        <b><a href="Computers.html" style="color: black; ">
                <- Back to How Do Computers Work </a></b><br><br>
    </div>
</div>




</html>